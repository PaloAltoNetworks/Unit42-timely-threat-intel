# 2025-12-15 (Monday): Real-World Example of Malicious Indirect Prompt Injection

## Authors:

- Beliz Kaleli, Shehroze Farooqi, Oleksii, Alex Starov

## Notes:

- We identified a real-world example of malicious indirect prompt injection.
- In this example, the actors attempted to bypass AI-based ad reviewers and promote scam products.
- This case uses multiple evasion techniques to hide its injected LLM prompts from security checks:
  - encoding
  - dynamic execution
  - obfuscation
  - semantic tricks
  - visually concealing

## URL For This Example:

- `hxxps[:]//reviewerpress[.]com/advertorial-maxvision-can/?lang=en`
